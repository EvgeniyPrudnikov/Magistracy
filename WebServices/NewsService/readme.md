##Реализованный сервис новостей 

###API

Реализованное API:

####Получение коллекции новостей с параметрами

 - Параметр start_dt=current_date (ISO8601) - означает текущую дату
 - Параметр days_diff=-2 означает минус 2 дня от текущей даты
 - Параметр source_uri= означает получение новостей из конкретного источника (одного из существующих в системе)
   если пустой, значит получить новости из всех существующих в системе источников

```
GET /news?start_dt=current_date&days_diff=-2&source_uri=
```
##### Пример ответа сервера:
```
{ 
	"items":[
			{ "_id": {
				"oid": dsksd12kjjksdfk32
				}
			 ,"news_uri": "/news/{news_id}"
			 ,"source_uri": "/sources/{id}"
			 ,"source_name": " ... " // имя источника новостей (пример: СБ Беларусь сегодня :) )
			 ,"news_date": "{news_date}" // дата появления/обновления новости
			 ,"news_title": " ... " // заголовок/имя новости
			 ,"preview":" ...  " // 1 - 2 абзаца тела новости
			}
			,
			{ "_id": {
				"obd": dsksd12kjjksdfk32
				}
			 ,"news_uri": "/sources/news/{news_id}"
			 ,"source_uri": "/sources/{id}"
			 ,"source_name": " ... "
			 ,"news_date": "{news_date}"
			 ,"news_title": " ... " 
			 ,"preview":" ...  " 
			}
			,
			{...}
			, 
			...
		]
}
```
#### Получение отдельной статьи:

Я не делал отдельную коллекцию для новостей, то есть сейчас этот запрос идет на коллекцию выше и ответ немного изменился в отличие от первоначального API

```
GET /news/{news_id}
```
##### Пример ответа сервера:

```

{ 
	 "items":[
	 		 { "_id": {
				 "oid": dsksd12kjjksdfk32
				}
			 ,"news_uri": "/news/{news_id}"
			 ,"source_uri": "/sources/{id}"
			 ,"source_name": " ... " // имя источника новостей (пример: СБ Беларусь сегодня :) )
			 ,"news_date": "{news_date}" // дата появления/обновления новости
			 ,"news_title": " ... " // заголовок/имя новости
			 ,"preview":" ...  " // 1 - 2 абзаца тела новости
			}
		]
}

``` 

####Cлужебные запросы для мержа двух баз для AP системы

Реализовано 2 вида запросов на забор и вставку данных. Они работают не через API сервиса, а напрямую к базе по сети.

Для забора данных используются такие запросы с таким же ответом сервиса.
Для вставки отдельный запрос который используя insert_many вставляет в базу, выбранную для merge into, разницу между базой merge from.

###Архитектура

Реализованна арихитектура для AP системы (см CAP теорему) 

![alt tag](https://github.com/EvgeniyPrudnikov/Magistracy/blob/master/WebServices/CAP/src/web5.png)

####Принцип работы

Как http срвер и балансировщик нагрузки был выбран nginx, также на нем настроен upstream. Он принимает запросы на localhost:80 и делит их 50/50 по двум сервисам, работаюшим на fastcgisocket1/2, которые в свою очередь подключены к своим базам данных(mongoDB) работающим на портах 27017/8.
При запуске сервиса определяется fastcgi monitor port и по нему определяется (мапингом) к какой базе данных поделючаться, сейчас это прописано в коде хардкодом, но чтобы этого не делать можно использовать например конфиг файлы, ну или придумывать логику как выбирать базу для подключений.  

####MergeNews Script

Реализован MergeNews script, который производит мерж данных после восстановления системы из состояния расщепления, а также при настройке системы на забор данных из разных источников (на картинке: 1ый сервер источники 1,2; 2ой сервер источники 2,3). Логика написана на c++ с использованием монго драйвера и библиотеки jsoncpp (очень удобная) и сделан исполняемы файл.Бинарник принимает 3 параметра: адрес базы данных в которую происходит мерж и адрес базы из которой забираются данные для мержа в форматах (db-host:db-port), а также разницу в днях от текущей даты базы для мержа (db-into) (напиример мерж данных за 10 дней от текущей даты). Скрипт работает следующим образом:

В двух потоках делаются запросы к базам, указаным во входных параметрах, после этого, полученые jsonы из базы парсятся с использованием библиотеки jsoncpp и происходит мерж (двойной цикл по json-у db-from, json-у db-into, если не нашли такой объект, добовляем его в вектор разницы ), далее если обнаружена разница в объектах, то эта разница записывается в db-into, с помощью insert_many().

Скрипт записывает только в 1 базу данных (db-into), так как запускается на каждой машине сети, и этого достаточно. Скрипт запускается каждую секунду.

###Нагрузочное тестирование

Тестирование проводилось с помощью yandex-tank на машине с intel i3 2500x4, 8Gb RAM, Ubuntu 16.04, с двумя сервисами и двумя mongoDB.
Запросы следующего вида:

```
GET /news?start_dt=current_date&days_diff=-2&source_uri=
```
```
GET /news/{news_id}
```
Современные новостные статьи не большого размера, обычные примерно от 1 - 5 kB, репортажи могут быть чуть болбше 15-30 kB, но учитывая ,что они встречаются реже, можно пологать, что стандартная новостная статья размеров примерно 2.5 kB (новости на Onliner.by и tut.by, bbc.com например). Пусть в день на 1 источнике добовляется 10 новостей (хотя обычно меньше), и у клиента настроено по умолчанию например 10 источников, что довольно много (обычно меньше), тогда стандартные запросы для получения колекции новостей за 2 дня будут возвращать криенту 10 * 10 * 2.5 * 2 = ~500 kB, а то и меньше, а запросы по получению конкретной новости всего 2.5 kB ( и много реже 15-30 kB). Так как у колекции новостей и у конкретной новости есть определенные критерии выбора из базы (по дате, по uri), то можно постоить индекс по этим полям, тогда скорость ответа сервиса не будет сильно зависить от размера базы (при очень больших базах и разростании индексов, конечно будет ), поэтому, для тестирования, достаточно было заполнить базу до размеров нескольких стандартных запросов, а именно на 1-2 MB.

При текущей конфигурации (nginx с upstream, 2 x fastcgi-daemon2, 2 x mongoDB, стандартный запрос ~500kB, + запросы по 3kB) получились следующие результаты тестирования:

Стрельба на разладку:
https://overload.yandex.net/4869#tab=test_data&tags=&plot_groups=main&machines=171&metrics=&slider_start=1482626612&slider_end=1482626732&compress_ratio=1

https://overload.yandex.net/4871#tab=test_data&tags=&plot_groups=main&machines=171&metrics=&slider_start=1482627242&slider_end=1482627362&compress_ratio=1

Видно, что после ~270 rpc процессор загружен на 100%, и соответсвенно квантили времени ответа начинают прыгать => для стабильной работы необходимо около 250 rpc.



