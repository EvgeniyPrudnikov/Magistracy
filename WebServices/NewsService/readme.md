##Реализованный сервис новостей 

###API

Реализованное API:

####Получение коллекции новостей с параметрами

 - Параметр start_dt=current_date (ISO8601) - означает текущую дату
 - Параметр days_diff=-2 означает минус 2 дня от текущей даты
 - Параметр source_uri= означает получение новостей из конкретного источника (одного из существующих в системе)
   если пустой, значит получить новости из всех существующих в системе источников

поле "preview" убрано и ответа сервера, за экономием трафика 
```
GET /news?start_dt=current_date&days_diff=-2&source_uri=
```
##### Пример ответа сервера:
```
{ 
	"items":[
			{ "_id": {
				"oid": dsksd12kjjksdfk32
				}
			 ,"news_uri": "/news/{news_id}"
			 ,"source_uri": "/sources/{id}"
			 ,"source_name": " ... " // имя источника новостей (пример: СБ Беларусь сегодня :) )
			 ,"news_date": "{news_date}" // дата появления/обновления новости
			 ,"news_title": " ... " // заголовок/имя новости
			}
			,
			{ "_id": {
				"obd": dsksd12kjjksdfk32
				}
			 ,"news_uri": "/sources/news/{news_id}"
			 ,"source_uri": "/sources/{id}"
			 ,"source_name": " ... "
			 ,"news_date": "{news_date}"
			 ,"news_title": " ... " 
			}
			,
			{...}
			, 
			...
		]
}
```
#### Получение отдельной статьи:

Используется отдельная коллекция, чтобы не нагружать запросы первого типа
```
GET /news/{news_id}
```
##### Пример ответа сервера:

```

{ 
	 "items":[
	 		 { 
			  "news_uri": "/news/{news_is}"
			 ,"source_uri": "/sources/{id}"
			 ,"source_name": " ... " // имя источника новостей (пример: СБ Беларусь сегодня :) )
			 ,"news_date": "{news_date}" // дата появления/обновления новости
			 ,"news_title": " ... " // заголовок/имя новости
			 ,"news_body_full":" html ...  " // тело новости
			 ,"news_author":" ... " 
			 ,"news_tags":" ... "
			}
		]
}

``` 

####Cлужебные запросы для мержа двух баз для AP системы

Реализовано 2 вида запросов: на забор и вставку данных. Они работают не через API сервиса, а напрямую к базе по сети.

Для забора данных используются такие же запросы с таким же ответом сервиса.
Для вставки отдельный запрос, который используя insert_many вставляет в базу, выбранную для merge into, разницу между базой merge from.

###Архитектура

Реализована арихитектура для AP системы (см CAP теорему) 

![alt tag](https://github.com/EvgeniyPrudnikov/Magistracy/blob/master/WebServices/CAP/src/web5.png)

####Принцип работы

Как http срвер и балансировщик нагрузки был выбран nginx, также на нем настроен upstream. Он принимает запросы на localhost:80 и делит их 50/50 по двум сервисам, работаюшим на fastcgisocket1/2, которые в свою очередь подключены к своим базам данных(mongoDB) работающим на портах 27017/8.
При запуске сервиса определяется fastcgi monitor port и по нему определяется (мапингом) к какой базе данных подключаться. Сейчас это прописано в коде хардкодом, но чтобы этого не делать можно использовать например конфиг файлы, ну или придумывать логику как выбирать базу для подключений.  

####MergeNews Script

Реализован MergeNews script, который производит мерж данных после восстановления системы из состояния расщепления, а также при настройке системы на забор данных из разных источников (на картинке: 1ый сервер источники 1,2; 2ой сервер источники 2,3). Логика написана на c++ с использованием монго драйвера и библиотеки jsoncpp (очень удобная) и сделан исполняемы файл. Бинарник принимает 3 параметра: адрес базы данных в которую происходит мерж и адрес базы из которой забираются данные для мержа в форматах (db-host:db-port), а также разницу в днях от текущей даты базы для мержа (db-into) (напиример мерж данных за 10 дней от текущей даты). Скрипт работает следующим образом:

В двух потоках делаются запросы к базам, указаным во входных параметрах, после этого, полученые json-ы из базы парсятся с использованием библиотеки jsoncpp и происходит мерж (двойной цикл по json-у db-from, json-у db-into, если не нашли такой объект, добовляем его в вектор разницы ), далее, если обнаружена разница в объектах, то эта разница записывается в db-into, с помощью insert_many().

Скрипт записывает только в 1 базу данных (db-into), так как запускается на каждой машине сети, и этого достаточно. Скрипт запускается каждую секунду.

Также, сейчас скрипт мержит только 1 коллекцию NewsCollection, но принцип работы с коллецией NewsItemCollection будет одинаковый, так как запросы на забор данных идентичны ( псевдокод: ```select * where news_date > db_date_now() + (-days_diff)``` )

###Нагрузочное тестирование

Тестирование проводилось с помощью yandex-tank на машине с intel i3 2500x2, 8Gb RAM, Ubuntu 16.04, с двумя сервисами и двумя mongoDB.
Запросы следующего вида:

```
GET /news?start_dt=current_date&days_diff=-2&source_uri=
```
```
GET /news/{news_id}
```
Современные новостные статьи не большого размера, обычные примерно от 1 - 5 kB, репортажи могут быть чуть болбше 15-30 kB, но учитывая ,что они встречаются реже, можно пологать, что стандартная новостная статья размеров примерно 2.5 kB (новости на Onliner.by и tut.by, bbc.com например). В коллекции новостей, для запроса с параметрами, не будем хранить тело новости,тогда 1 объект будет весить примерно ~300 Bytes. Пусть в день на 1 источнике добовляется 10 новостей, и у клиента настроено по умолчанию например 10 источников, тогда стандартные запросы для получения колекции новостей за 2 дня будут возвращать криенту ```10 * 10 * 2 * 300 B = ~60 kB```, а то и меньше, а запросы по получению конкретной новости всего 2.5 kB ( и много реже 15-30 kB). Так как у колекции новостей и у конкретной новости есть определенные критерии выбора из базы (по дате, по uri), то можно постоить индекс по этим полям, тогда скорость ответа сервиса не будет сильно зависить от размера базы (при очень больших базах и разростании индексов, конечно будет ), поэтому, для тестирования, достаточно было заполнить базу до размеров нескольких стандартных запросов, а именно на 100-300 kB.

При текущей конфигурации (nginx с upstream, 2 x fastcgi-daemon2, 2 x mongoDB, стандартный запрос ~60kB, + запросы по 3kB) получились следующие результаты тестирования:

Стрельба на разладку:

[rpc 1 - 3000, line, analysis](https://overload.yandex.net/4898#tab=test_data&tags=&plot_groups=main&machines=171&metrics=&slider_start=1482661921&slider_end=1482662113&compress_ratio=1)

[rpc 1 - 3000, line, monitoring](https://overload.yandex.net/4898#tab=monitoring&tags=&plot_groups=main&machines=171&metrics=&slider_start=1482661921&slider_end=1482662113&compress_ratio=1)

Видно, что где-то на 1500 - 1600 rpc процессор загружен почти на 100%, и на графиках анализа видно, что квантили времени начинают ползти вверх и появляются сетевые и http ошибки

Уменьшим rpc до 1500 

[rpc 1500 analysis](https://overload.yandex.net/4904#tab=test_data&tags=&plot_groups=main&machines=171&metrics=&slider_start=1482663922&slider_end=1482664341&compress_ratio=1)

[rpc 1500 monitoring](https://overload.yandex.net/4904#tab=monitoring&tags=&plot_groups=main&machines=171&metrics=&slider_start=1482663922&slider_end=1482664341&compress_ratio=1)

Получается все равно много, иногда процессор поднимается до ~100% 
Уменьшим до 1300 

[rpc 1300 analysis](https://overload.yandex.net/4910#tab=test_data&tags=&plot_groups=main&machines=&metrics=&slider_start=1482665115&slider_end=1482665533)

[rpc 1300 monitoring](https://overload.yandex.net/4910#tab=monitoring&tags=&plot_groups=main&machines=171&metrics=&slider_start=1482665116&slider_end=1482665533&compress_ratio=1)

Все равно процессор подводит :( 

Уменьшим до 1100

[rpc 1100 analysis](https://overload.yandex.net/4917#tab=test_data&tags=&plot_groups=main&machines=171&metrics=&slider_start=1482666495&slider_end=1482666912&compress_ratio=1)

[rpc 1100 monitoring](https://overload.yandex.net/4917#tab=monitoring&tags=&plot_groups=main&machines=171&metrics=&slider_start=1482666495&slider_end=1482666912&compress_ratio=1)

Видно, что уже ситуация получше, есть скачки процессора(возможно из-за системных штук)
Можно говорить, что этот уровень - оптимальный

По распределению времен ответа видно, что большинство ответов приходят за 1 - 5 ms 
[responce times distribution](https://overload.yandex.net/4917#tab=test_data&tags=&plot_groups=additional&machines=171&metrics=&slider_start=1482666495&slider_end=1482666912&compress_ratio=1)

По таблице квантилей ответа [responce times distribution](https://overload.yandex.net/4917#tab=test_data&tags=&plot_groups=tables&machines=171&metrics=&slider_start=1482666495&slider_end=1482666912&compress_ratio=1) 
видно, что квантиль в 92% - отвечает за 5ms, 98% - 10 ms, 99% - 20 ms, ну и конечно есть какие-то выбросы, например в 40 - 80 ms, однако это всего 0.065% (то есть примерно ~половина 1 десятой процента) от общего числа запросов, возможно это связано с активностями системы.
